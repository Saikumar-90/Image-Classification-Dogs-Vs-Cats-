{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h70Gb2Ffr1Rh"
      },
      "outputs": [],
      "source": [
        "# Dogs vs Cats Classification using Two Models (Simple CNN and MobileNetV2 (Transfer Learning))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the libraries\n"
      ],
      "metadata": {
        "id": "fxR7DuPgtaQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Loads images,Resize's them,normalise pixels\n",
        "import os, pathlib   # Navigate Downloaded folders\n",
        "\n",
        "print(\"TensorFlow_Version : \", tf.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "QKSP0v06tlLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Cats & Dogs Dataset\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
        "train_ds = dataset['train']\n"
      ],
      "metadata": {
        "id": "yFk7h6wAzjRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use a subset for faster training\n",
        "\n",
        "LIMIT_TRAIN = 4000     # Number of training samples\n",
        "LIMIT_VAL = 1000       # Number of validation samples\n",
        "\n",
        "train_data_raw = train_ds.take(LIMIT_TRAIN)\n",
        "val_data_raw = train_ds.skip(LIMIT_TRAIN).take(LIMIT_VAL)\n"
      ],
      "metadata": {
        "id": "6EcmlzP7pcMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PreProcessing (Resize + Normalize)\n",
        "\n",
        "IMG_SIZE = 160\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data_raw.map(preprocess).batch(32).prefetch(1)  # MAP apply a function to every item in the dataset\n",
        "val_data = val_data_raw.map(preprocess).batch(32).prefetch(1)\n"
      ],
      "metadata": {
        "id": "w8dAsol3BgL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building Model 1 – Simple CNN\n",
        "\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(160, 160, 3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "nQhY2ySpX9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure  the model for training\n",
        "\n",
        "model_1.compile(\n",
        "    optimizer=\"Adam\",\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "id": "L5fKaiOZa6R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(\n",
        "    train_data,\n",
        "    epochs=5,\n",
        "    validation_data=val_data\n",
        ")\n"
      ],
      "metadata": {
        "id": "u7CR43UqdrC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Training – Accuracy & Loss Curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Extract values from history object\n",
        "acc = history_1.history['accuracy']\n",
        "val_acc = history_1.history['val_accuracy']\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# 2. Create figure\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# 3. Accuracy graph\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy (Model 1 - Simple CNN)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# 4. Loss graph\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss (Model 1 - Simple CNN)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CcFvoJEihjmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate CNN on Validation Data\n",
        "\n",
        "val_loss, val_acc = model_1.evaluate(val_data)\n",
        "print(\"Final Validation Loss (Model 1):\", val_loss)\n",
        "print(\"Final Validation Accuracy (Model 1):\", val_acc)\n"
      ],
      "metadata": {
        "id": "Tz6qxghMscQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 2 - MobileNetV2\n",
        "\n",
        "IMG_SIZE = 160\n",
        "\n",
        "def preprocess_mnet(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_data_m2 = train_data_raw.map(preprocess_mnet).batch(32).prefetch(1)\n",
        "val_data_m2   = val_data_raw.map(preprocess_mnet).batch(32).prefetch(1)\n"
      ],
      "metadata": {
        "id": "hxOVoVIpumxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False  # freeze base model weights\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "id": "lp9jtqJ9xRkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "V7iwZ-Le020z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train (Transfer Learning)\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    train_data_m2,\n",
        "    epochs=5,\n",
        "    validation_data=val_data_m2\n",
        ")\n"
      ],
      "metadata": {
        "id": "-KFKZaZw06b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Accuracy & Loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc2 = history_2.history['accuracy']\n",
        "val_acc2 = history_2.history['val_accuracy']\n",
        "loss2 = history_2.history['loss']\n",
        "val_loss2 = history_2.history['val_loss']\n",
        "\n",
        "epochs2 = range(1, len(acc2) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs2, acc2, label='Training Accuracy (Model 2)')\n",
        "plt.plot(epochs2, val_acc2, label='Validation Accuracy (Model 2)')\n",
        "plt.title('Model 2 - Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs2, loss2, label='Training Loss (Model 2)')\n",
        "plt.plot(epochs2, val_loss2, label='Validation Loss (Model 2)')\n",
        "plt.title('Model 2 - Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "askLQjZY1D6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on Validation Data\n",
        "val_loss_2, val_acc_2 = model_2.evaluate(val_data_m2)\n",
        "print(\"Final Validation Loss (Model 2):\", val_loss_2)\n",
        "print(\"Final Validation Accuracy (Model 2):\", val_acc_2)\n"
      ],
      "metadata": {
        "id": "TTDuoGuo2Wzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing Model 1 vs Model 2\n",
        "\n",
        "m1_train_last = history_1.history['accuracy'][-1]\n",
        "m1_val_last   = history_1.history['val_accuracy'][-1]\n",
        "\n",
        "m2_train_last = history_2.history['accuracy'][-1]\n",
        "m2_val_last   = history_2.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"Model 1 - Train:\", m1_train_last, \" Val:\", m1_val_last)\n",
        "print(\"Model 2 - Train:\", m2_train_last, \" Val:\", m2_val_last)\n"
      ],
      "metadata": {
        "id": "D_w8BPuC2ddt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real Image Prediction (Dog vs Cat)\n",
        "\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "    # Load and display the image\n",
        "    image = Image.open(file_name)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Preprocess image\n",
        "    image = image.resize((160, 160))\n",
        "    img_array = np.array(image)\n",
        "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # make it batch of 1\n",
        "\n",
        "    # Predict\n",
        "    prediction = model_2.predict(img_array)[0][0]\n",
        "\n",
        "    if prediction > 0.5:\n",
        "        print(f\"Prediction: Dog ({prediction:.2f})\")\n",
        "    else:\n",
        "        print(f\"Prediction: Cat ({1 - prediction:.2f})\")\n"
      ],
      "metadata": {
        "id": "5P8mySpK25XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-dYBnBty4lOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
